{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter.10.2 MVLoR for Several Sample\n",
    "\n",
    "PA10.2에서는 MVLoR을 Several sample을 통해서 구현한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import basic_nodes as nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.1 dataset_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_generator:\n",
    "    def __init__(self, feature_dim, n_sample = 300, noise_factor = 0., direction = 1):\n",
    "        self._feature_dim = feature_dim\n",
    "        self._n_sample = n_sample\n",
    "        self._noise_factor = noise_factor\n",
    "        self._direction = direction\n",
    "    \n",
    "        self._init_feature_dict()\n",
    "        self._init_t_th()\n",
    "    def _init_feature_dict(self):\n",
    "        self._feature_dict = dict()\n",
    "        for feature_idx in range(1, self._feature_dim + 1):\n",
    "            x_dict = {'mean':0, 'std':1}\n",
    "            self._feature_dict[feature_idx] = x_dict\n",
    "        \n",
    "    def _init_t_th(self):\n",
    "        self._t_th = [0] + [1 for i in range(self._feature_dim)]\n",
    "        \n",
    "    def set_feature_dict(self, feature_dict):\n",
    "        if len(feature_dict) != self._feature_dim:\n",
    "            class FeatureDictError(Exception):\n",
    "                pass\n",
    "            raise FeatureDictError('The length of \"feature_dict\" should be equal to \"feature_dim\"')\n",
    "        else:\n",
    "            self._feature_dict = feature_dict\n",
    "    def set_t_th(self, t_th_list):\n",
    "        if len(t_th_list) != len(self._t_th):\n",
    "            class t_th_Error(Exception):\n",
    "                pass\n",
    "            raise t_th_Error('The length of \"t_th_list\" should be equal to \"t_th_list\"')\n",
    "        else:\n",
    "            self._t_th = t_th_list\n",
    "### Start\n",
    "    def make_dataset(self):\n",
    "        x_data = \n",
    "        y = \n",
    "        \n",
    "        for feature_idx in range(1, self._feature_dim + 1):\n",
    "            feature_dict = self._feature_dict[feature_idx]\n",
    "            data = np.random.normal(loc = , scale = ,\n",
    "                                    size = )\n",
    "            x_data = np.hstack()\n",
    "            y += \n",
    "        y +=\n",
    "        y_noise = y + \n",
    "        \n",
    "        if self._direction > 0:\n",
    "            y_data = (y_noise > 0).astype(np.int)\n",
    "        else:\n",
    "            y_data = (y_noise < 0).astype(np.int)\n",
    "        \n",
    "        data = np.hstack()\n",
    "        return data\n",
    "### End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_batch(data, batch_idx):\n",
    "    if batch_idx is n_batch -1:\n",
    "        batch = data[batch_idx*batch_size:]\n",
    "    else:\n",
    "        batch = data[batch_idx*batch_size : (batch_idx + 1)* batch_size]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.2 Affine_Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine_Function:\n",
    "    def __init__(self):\n",
    "        self._feature_dim = feature_dim\n",
    "        \n",
    "        self._Z1_list = [None]*(self._feature_dim + 1)\n",
    "        self._Z2_list = self._Z1_list.copy()\n",
    "        \n",
    "        self._dZ1_list, self._dZ2_list = self._Z1_list.copy(), self._Z1_list.copy()\n",
    "        self._dTh_list = self._Z1_list.copy()\n",
    "        \n",
    "        self.node_imp()\n",
    "        self.random_initialization()\n",
    "        \n",
    "    def node_imp(self):\n",
    "        self._node1 = [None] + [nodes.mul_node() for _ in range(self._feature_dim)]\n",
    "        self._node2 = [None] + [nodes.plus_node() for _ in range(self._feature_dim)]\n",
    "### Start\n",
    "    def random_initialization(self):\n",
    "        r_feature_dim = 1/np.power(self._feature_dim, 0.5)\n",
    "        self._Th = np.random.uniform(low = ,\n",
    "                                     high = ,\n",
    "                                     size = )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        for node_idx in range(1, self._feature_dim + 1):\n",
    "            self._Z1_list[node_idx] = \n",
    "        self._Z2_list[1] = \n",
    "        for node_idx in range(2, self._feature_dim + 1):\n",
    "            self._Z2_list[node_idx] = \n",
    "        return self._Z2_list[-1]\n",
    "    \n",
    "    def backward(self, dZ2_last, lr):\n",
    "        self._dZ2_list[-1] = \n",
    "        \n",
    "        for node_idx in reversed(range(1, self._feature_dim + 1)):\n",
    "            dZ2, dZ1 = \n",
    "            self._dZ2_list[node_idx-1] = \n",
    "            self._dZ1_list[node_idx] = \n",
    "        \n",
    "        self._dTh_list[0] = \n",
    "        \n",
    "        for node_idx in reversed(range(1, self._feature_dim + 1)):\n",
    "            dTh, _ = \n",
    "            self._dTh_list[node_idx] = \n",
    "        for th_idx in range(self._Th.shape[0]):\n",
    "            self._Th[th_idx] = \n",
    "\n",
    "        return self._Th\n",
    "    \n",
    "    def get_Th(self):\n",
    "        return self._Th\n",
    "### End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.3 Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self._Pred = None\n",
    "### Start\n",
    "    def forward(self, Z):\n",
    "        self._Pred = \n",
    "        return self._Pred\n",
    "    \n",
    "    def backward(self, dPred):\n",
    "        partial = \n",
    "        dZ = \n",
    "        return dZ\n",
    "### End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.4 BinaryCrossEntropy_Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryCrossEntropy_Loss:\n",
    "    def __init__(self):\n",
    "        self._Y, self._Pred = None, None\n",
    "        self._mean_node = nodes.mean_node()\n",
    "### Start\n",
    "    def forward(self, Y, Pred):\n",
    "        self._Y, self._Pred = \n",
    "        Loss = \n",
    "        J = \n",
    "        return J\n",
    "\n",
    "    def backward(self):\n",
    "        dLoss = \n",
    "        dPred =\n",
    "        return dPred\n",
    "### End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.5 MVLoR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MVLoR:\n",
    "    def __init__(self):\n",
    "        self._feature_dim = feature_dim\n",
    "        self._affine = Affine_Function()\n",
    "        self._sigmoid = Sigmoid()\n",
    "### Start\n",
    "    def forward(self, X):\n",
    "        Z =\n",
    "        Pred =\n",
    "        return Pred\n",
    "\n",
    "    def backward(self, dPred, lr):\n",
    "        dZ = \n",
    "        self._affine.backward(dZ,lr)\n",
    "    \n",
    "    def get_Th(self):\n",
    "        return self._affine.get_Th()\n",
    "### End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.6 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_visualizer():\n",
    "    global th_accum, loss_list\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (30, 10))\n",
    "    fig.subplots_adjust(hspace = 0.3)\n",
    "    ax.set_title(r'$\\vec{\\theta}$' + ' Update')\n",
    "    \n",
    "    for feature_idx in range(feature_dim + 1):\n",
    "        \n",
    "        ax.plot(th_accum[feature_idx, :], label = r'$\\theta_{%d}$'%feature_idx)\n",
    "        \n",
    "    ax.legend(loc = 'center left',\n",
    "              bbox_to_anchor = (1,0.5))\n",
    "    \n",
    "    iter_ticks = np.linspace(0, th_accum.shape[1],10).astype(np.int)\n",
    "    ax.set_xticks(iter_ticks)\n",
    "def result_tracker():\n",
    "    global iter_idx, check_freq\n",
    "    global th_accum, affine\n",
    "    \n",
    "    if iter_idx % check_freq == 0:\n",
    "        th_accum = np.hstack((th_accum, model.get_Th()))\n",
    "        cost_list.append(1)\n",
    "    iter_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.7 Dataset Preparation\n",
    "\"\"\"<br>\n",
    "feature_dim: 4<br>\n",
    "noise_factor: 0.<br>\n",
    "direction: 1<br>\n",
    "n_sample: 500<br>\n",
    "batch_size: 8<br>\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start\n",
    "feature_dim = \n",
    "noise_factor = \n",
    "direction  = \n",
    "n_sample = \n",
    "\n",
    "data_gen = dataset_generator(feature_dim = feature_dim,\n",
    "                             n_sample = n_sample,\n",
    "                             noise_factor = noise_factor,\n",
    "                             direction = direction)\n",
    "data = data_gen.make_dataset()\n",
    "\n",
    "batch_size = \n",
    "n_batch = np.ceil().astype(int)\n",
    "### End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.8\n",
    "Affine_Function와 sigmoid, BinaryCrossEntropy_Loss를 생성합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start\n",
    "model = \n",
    "BCE_cost = \n",
    "\n",
    "th_accum = \n",
    "cost_list = []\n",
    "\n",
    "epochs, lr =\n",
    "iter_idx, check_freq = \n",
    "### End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step.9 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    np.random.shuffle(data)\n",
    "### Start\n",
    "    for batch_idx in range(n_batch):\n",
    "        batch = get_data_batch(data, batch_idx)\n",
    "        X, Y = batch[:,:-1],batch[:,-1]\n",
    "        \n",
    "        Pred = model.forward(X)\n",
    "        J = BCE_cost.forward(Y,Pred)\n",
    "        \n",
    "        dPred = BCE_cost.backward()\n",
    "        model.backward(dPred, lr)\n",
    "### End\n",
    "        result_tracker()\n",
    "result_visualizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output** \n",
    "<img src='./img_10/10_03.png' width = 700>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
